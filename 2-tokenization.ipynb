{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T19:16:12.835431Z",
     "start_time": "2025-12-22T19:16:12.833078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from importlib import reload"
   ],
   "id": "89b2f7641108fd8d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T19:16:13.992506Z",
     "start_time": "2025-12-22T19:16:13.990421Z"
    }
   },
   "cell_type": "code",
   "source": "from source import tokenizator as tk",
   "id": "84893e3f6e5bae41",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-22T19:16:14.889285Z",
     "start_time": "2025-12-22T19:16:14.884159Z"
    }
   },
   "source": [
    "df = pd.read_pickle('dfs/preprocessed-df.pkl')\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              prompt  \\\n",
       "0  You happen to know that Tim and Harry have rec...   \n",
       "0  You happen to know that Tim and Harry have rec...   \n",
       "0  You happen to know that Tim and Harry have rec...   \n",
       "0  You happen to know that Tim and Harry have rec...   \n",
       "1  \\n Even if it is true that we routinely rely o...   \n",
       "\n",
       "                                           professor  \\\n",
       "0  That's a great question! You see, our brains a...   \n",
       "0  Of course, you could be wrong! But here's the ...   \n",
       "0  Ah, great example! This is where the concept o...   \n",
       "0  Exactly! Our minds are wired to seek patterns ...   \n",
       "1  Well, my inquisitive student, that's a great q...   \n",
       "\n",
       "                                             student  \n",
       "0  Professor, I was thinking about how I conclude...  \n",
       "0  But isn't that just an assumption? I mean, I c...  \n",
       "0  That makes sense, I guess. But what about case...  \n",
       "0  Yeah, I think so. It's like, our brains are al...  \n",
       "1  Professor Phil, do we always choose the simple...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>professor</th>\n",
       "      <th>student</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You happen to know that Tim and Harry have rec...</td>\n",
       "      <td>That's a great question! You see, our brains a...</td>\n",
       "      <td>Professor, I was thinking about how I conclude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You happen to know that Tim and Harry have rec...</td>\n",
       "      <td>Of course, you could be wrong! But here's the ...</td>\n",
       "      <td>But isn't that just an assumption? I mean, I c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You happen to know that Tim and Harry have rec...</td>\n",
       "      <td>Ah, great example! This is where the concept o...</td>\n",
       "      <td>That makes sense, I guess. But what about case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You happen to know that Tim and Harry have rec...</td>\n",
       "      <td>Exactly! Our minds are wired to seek patterns ...</td>\n",
       "      <td>Yeah, I think so. It's like, our brains are al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n Even if it is true that we routinely rely o...</td>\n",
       "      <td>Well, my inquisitive student, that's a great q...</td>\n",
       "      <td>Professor Phil, do we always choose the simple...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T19:16:21.745176Z",
     "start_time": "2025-12-22T19:16:21.522357Z"
    }
   },
   "cell_type": "code",
   "source": "nlp = spacy.load('en_core_web_sm')",
   "id": "8736c8b0962313b8",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T19:36:59.790099Z",
     "start_time": "2025-12-22T19:36:59.699141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reload(tk)\n",
    "df_clean = tk.tag_df_with_spacy(df=df, nlp= nlp, column_names=['professor', 'student'])"
   ],
   "id": "6f67a3e8378ff827",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning column \"professor\"...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[30]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m reload(tk)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m df_clean = \u001B[43mtk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtag_df_with_spacy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnlp\u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mnlp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn_names\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mprofessor\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mstudent\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python_files\\zipf-law-for-information-theory\\source\\tokenizator.py:60\u001B[39m, in \u001B[36mtag_df_with_spacy\u001B[39m\u001B[34m(df, nlp, column_names)\u001B[39m\n\u001B[32m     58\u001B[39m         doc = nlp(text)\n\u001B[32m     59\u001B[39m         clean_tokens = tag_paragraph_with_spacy(doc)\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m         \u001B[43mdf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mat\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_name\u001B[49m\u001B[43m]\u001B[49m = [clean_tokens]\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python_files\\zipf-law-for-information-theory\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:2583\u001B[39m, in \u001B[36m_AtIndexer.__setitem__\u001B[39m\u001B[34m(self, key, value)\u001B[39m\n\u001B[32m   2580\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(is_scalar(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m key):\n\u001B[32m   2581\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mInvalid call for scalar access (setting)!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m2583\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m = value\n\u001B[32m   2584\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m   2586\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().\u001B[34m__setitem__\u001B[39m(key, value)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python_files\\zipf-law-for-information-theory\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:911\u001B[39m, in \u001B[36m_LocationIndexer.__setitem__\u001B[39m\u001B[34m(self, key, value)\u001B[39m\n\u001B[32m    908\u001B[39m \u001B[38;5;28mself\u001B[39m._has_valid_setitem_indexer(key)\n\u001B[32m    910\u001B[39m iloc = \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.name == \u001B[33m\"\u001B[39m\u001B[33miloc\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m.obj.iloc\n\u001B[32m--> \u001B[39m\u001B[32m911\u001B[39m \u001B[43miloc\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_setitem_with_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python_files\\zipf-law-for-information-theory\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1942\u001B[39m, in \u001B[36m_iLocIndexer._setitem_with_indexer\u001B[39m\u001B[34m(self, indexer, value, name)\u001B[39m\n\u001B[32m   1939\u001B[39m \u001B[38;5;66;03m# align and set the values\u001B[39;00m\n\u001B[32m   1940\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m take_split_path:\n\u001B[32m   1941\u001B[39m     \u001B[38;5;66;03m# We have to operate column-wise\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1942\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_setitem_with_indexer_split_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1943\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1944\u001B[39m     \u001B[38;5;28mself\u001B[39m._setitem_single_block(indexer, value, name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python_files\\zipf-law-for-information-theory\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1982\u001B[39m, in \u001B[36m_iLocIndexer._setitem_with_indexer_split_path\u001B[39m\u001B[34m(self, indexer, value, name)\u001B[39m\n\u001B[32m   1977\u001B[39m     \u001B[38;5;28mself\u001B[39m._setitem_with_indexer_frame_value(indexer, value, name)\n\u001B[32m   1979\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m np.ndim(value) == \u001B[32m2\u001B[39m:\n\u001B[32m   1980\u001B[39m     \u001B[38;5;66;03m# TODO: avoid np.ndim call in case it isn't an ndarray, since\u001B[39;00m\n\u001B[32m   1981\u001B[39m     \u001B[38;5;66;03m#  that will construct an ndarray, which will be wasteful\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1982\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_setitem_with_indexer_2d_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1984\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(ilocs) == \u001B[32m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m lplane_indexer == \u001B[38;5;28mlen\u001B[39m(value) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scalar(pi):\n\u001B[32m   1985\u001B[39m     \u001B[38;5;66;03m# We are setting multiple rows in a single column.\u001B[39;00m\n\u001B[32m   1986\u001B[39m     \u001B[38;5;28mself\u001B[39m._setitem_single_column(ilocs[\u001B[32m0\u001B[39m], value, pi)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python_files\\zipf-law-for-information-theory\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:2048\u001B[39m, in \u001B[36m_iLocIndexer._setitem_with_indexer_2d_value\u001B[39m\u001B[34m(self, indexer, value)\u001B[39m\n\u001B[32m   2046\u001B[39m     value = np.array(value, dtype=\u001B[38;5;28mobject\u001B[39m)\n\u001B[32m   2047\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(ilocs) != value.shape[\u001B[32m1\u001B[39m]:\n\u001B[32m-> \u001B[39m\u001B[32m2048\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   2049\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mMust have equal len keys and value when setting with an ndarray\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2050\u001B[39m     )\n\u001B[32m   2052\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, loc \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(ilocs):\n\u001B[32m   2053\u001B[39m     value_col = value[:, i]\n",
      "\u001B[31mValueError\u001B[39m: Must have equal len keys and value when setting with an ndarray"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T19:35:07.693785Z",
     "start_time": "2025-12-22T19:35:07.687815Z"
    }
   },
   "cell_type": "code",
   "source": "df_clean",
   "id": "8ecbde1b8ba4dee5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               prompt  \\\n",
       "0   You happen to know that Tim and Harry have rec...   \n",
       "0   You happen to know that Tim and Harry have rec...   \n",
       "0   You happen to know that Tim and Harry have rec...   \n",
       "0   You happen to know that Tim and Harry have rec...   \n",
       "1   \\n Even if it is true that we routinely rely o...   \n",
       "..                                                ...   \n",
       "19  \\n\\n The only major work that we possess of Ju...   \n",
       "19  \\n\\n The only major work that we possess of Ju...   \n",
       "19  \\n\\n The only major work that we possess of Ju...   \n",
       "19  \\n\\n The only major work that we possess of Ju...   \n",
       "19  \\n\\n The only major work that we possess of Ju...   \n",
       "\n",
       "                                            professor  \\\n",
       "0   That's a great question! You see, our brains a...   \n",
       "0   Of course, you could be wrong! But here's the ...   \n",
       "0   Ah, great example! This is where the concept o...   \n",
       "0   Exactly! Our minds are wired to seek patterns ...   \n",
       "1   Well, my inquisitive student, that's a great q...   \n",
       "..                                                ...   \n",
       "19  That's a great point. Family background can in...   \n",
       "19  Not at all! Poetry and philosophy have long be...   \n",
       "19  Unfortunately, yes, the work is lost, but what...   \n",
       "19  Ah, yes! The dating of the Dialoghi d'amore is...   \n",
       "19  You're welcome! I'm glad I could help you expl...   \n",
       "\n",
       "                                              student  \\\n",
       "0   Professor, I was thinking about how I conclude...   \n",
       "0   But isn't that just an assumption? I mean, I c...   \n",
       "0   That makes sense, I guess. But what about case...   \n",
       "0   Yeah, I think so. It's like, our brains are al...   \n",
       "1   Professor Phil, do we always choose the simple...   \n",
       "..                                                ...   \n",
       "19  That makes sense. But what about his family ba...   \n",
       "19  I see what you mean. But what about his poetry...   \n",
       "19  That's a great point. I never thought about it...   \n",
       "19  I feel like I have a better sense of Judah Abr...   \n",
       "19  I never thought about how something like that ...   \n",
       "\n",
       "                                         prompt_clean  \\\n",
       "0   ['happen', 'know', 'tim', 'harry', 'recently',...   \n",
       "0   ['happen', 'know', 'tim', 'harry', 'recently',...   \n",
       "0   ['happen', 'know', 'tim', 'harry', 'recently',...   \n",
       "0   ['happen', 'know', 'tim', 'harry', 'recently',...   \n",
       "1   ['true', 'routinely', 'rely', 'abductive', 're...   \n",
       "..                                                ...   \n",
       "19  ['major', 'work', 'possess', 'judah', 'abraban...   \n",
       "19  ['major', 'work', 'possess', 'judah', 'abraban...   \n",
       "19  ['major', 'work', 'possess', 'judah', 'abraban...   \n",
       "19  ['major', 'work', 'possess', 'judah', 'abraban...   \n",
       "19  ['major', 'work', 'possess', 'judah', 'abraban...   \n",
       "\n",
       "                                      professor_clean  \\\n",
       "0   ['exactly', 'mind', 'wire', 'seek', 'pattern',...   \n",
       "0   ['exactly', 'mind', 'wire', 'seek', 'pattern',...   \n",
       "0   ['exactly', 'mind', 'wire', 'seek', 'pattern',...   \n",
       "0   ['exactly', 'mind', 'wire', 'seek', 'pattern',...   \n",
       "1   ['excellent', 'question', 'critic', 'abduction...   \n",
       "..                                                ...   \n",
       "19  ['welcome', 'glad', 'help', 'explore', 'idea',...   \n",
       "19  ['welcome', 'glad', 'help', 'explore', 'idea',...   \n",
       "19  ['welcome', 'glad', 'help', 'explore', 'idea',...   \n",
       "19  ['welcome', 'glad', 'help', 'explore', 'idea',...   \n",
       "19  ['welcome', 'glad', 'help', 'explore', 'idea',...   \n",
       "\n",
       "                                        student_clean  \n",
       "0   ['yeah', 'think', 'like', 'brain', 'try', 'fin...  \n",
       "0   ['yeah', 'think', 'like', 'brain', 'try', 'fin...  \n",
       "0   ['yeah', 'think', 'like', 'brain', 'try', 'fin...  \n",
       "0   ['yeah', 'think', 'like', 'brain', 'try', 'fin...  \n",
       "1   ['mean', 'professor', 'like', 'need', 'strike'...  \n",
       "..                                                ...  \n",
       "19  ['think', 'like', 'impact', 'understanding', '...  \n",
       "19  ['think', 'like', 'impact', 'understanding', '...  \n",
       "19  ['think', 'like', 'impact', 'understanding', '...  \n",
       "19  ['think', 'like', 'impact', 'understanding', '...  \n",
       "19  ['think', 'like', 'impact', 'understanding', '...  \n",
       "\n",
       "[83 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>professor</th>\n",
       "      <th>student</th>\n",
       "      <th>prompt_clean</th>\n",
       "      <th>professor_clean</th>\n",
       "      <th>student_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You happen to know that Tim and Harry have rec...</td>\n",
       "      <td>That's a great question! You see, our brains a...</td>\n",
       "      <td>Professor, I was thinking about how I conclude...</td>\n",
       "      <td>['happen', 'know', 'tim', 'harry', 'recently',...</td>\n",
       "      <td>['exactly', 'mind', 'wire', 'seek', 'pattern',...</td>\n",
       "      <td>['yeah', 'think', 'like', 'brain', 'try', 'fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You happen to know that Tim and Harry have rec...</td>\n",
       "      <td>Of course, you could be wrong! But here's the ...</td>\n",
       "      <td>But isn't that just an assumption? I mean, I c...</td>\n",
       "      <td>['happen', 'know', 'tim', 'harry', 'recently',...</td>\n",
       "      <td>['exactly', 'mind', 'wire', 'seek', 'pattern',...</td>\n",
       "      <td>['yeah', 'think', 'like', 'brain', 'try', 'fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You happen to know that Tim and Harry have rec...</td>\n",
       "      <td>Ah, great example! This is where the concept o...</td>\n",
       "      <td>That makes sense, I guess. But what about case...</td>\n",
       "      <td>['happen', 'know', 'tim', 'harry', 'recently',...</td>\n",
       "      <td>['exactly', 'mind', 'wire', 'seek', 'pattern',...</td>\n",
       "      <td>['yeah', 'think', 'like', 'brain', 'try', 'fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You happen to know that Tim and Harry have rec...</td>\n",
       "      <td>Exactly! Our minds are wired to seek patterns ...</td>\n",
       "      <td>Yeah, I think so. It's like, our brains are al...</td>\n",
       "      <td>['happen', 'know', 'tim', 'harry', 'recently',...</td>\n",
       "      <td>['exactly', 'mind', 'wire', 'seek', 'pattern',...</td>\n",
       "      <td>['yeah', 'think', 'like', 'brain', 'try', 'fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n Even if it is true that we routinely rely o...</td>\n",
       "      <td>Well, my inquisitive student, that's a great q...</td>\n",
       "      <td>Professor Phil, do we always choose the simple...</td>\n",
       "      <td>['true', 'routinely', 'rely', 'abductive', 're...</td>\n",
       "      <td>['excellent', 'question', 'critic', 'abduction...</td>\n",
       "      <td>['mean', 'professor', 'like', 'need', 'strike'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\n\\n The only major work that we possess of Ju...</td>\n",
       "      <td>That's a great point. Family background can in...</td>\n",
       "      <td>That makes sense. But what about his family ba...</td>\n",
       "      <td>['major', 'work', 'possess', 'judah', 'abraban...</td>\n",
       "      <td>['welcome', 'glad', 'help', 'explore', 'idea',...</td>\n",
       "      <td>['think', 'like', 'impact', 'understanding', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\n\\n The only major work that we possess of Ju...</td>\n",
       "      <td>Not at all! Poetry and philosophy have long be...</td>\n",
       "      <td>I see what you mean. But what about his poetry...</td>\n",
       "      <td>['major', 'work', 'possess', 'judah', 'abraban...</td>\n",
       "      <td>['welcome', 'glad', 'help', 'explore', 'idea',...</td>\n",
       "      <td>['think', 'like', 'impact', 'understanding', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\n\\n The only major work that we possess of Ju...</td>\n",
       "      <td>Unfortunately, yes, the work is lost, but what...</td>\n",
       "      <td>That's a great point. I never thought about it...</td>\n",
       "      <td>['major', 'work', 'possess', 'judah', 'abraban...</td>\n",
       "      <td>['welcome', 'glad', 'help', 'explore', 'idea',...</td>\n",
       "      <td>['think', 'like', 'impact', 'understanding', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\n\\n The only major work that we possess of Ju...</td>\n",
       "      <td>Ah, yes! The dating of the Dialoghi d'amore is...</td>\n",
       "      <td>I feel like I have a better sense of Judah Abr...</td>\n",
       "      <td>['major', 'work', 'possess', 'judah', 'abraban...</td>\n",
       "      <td>['welcome', 'glad', 'help', 'explore', 'idea',...</td>\n",
       "      <td>['think', 'like', 'impact', 'understanding', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\\n\\n The only major work that we possess of Ju...</td>\n",
       "      <td>You're welcome! I'm glad I could help you expl...</td>\n",
       "      <td>I never thought about how something like that ...</td>\n",
       "      <td>['major', 'work', 'possess', 'judah', 'abraban...</td>\n",
       "      <td>['welcome', 'glad', 'help', 'explore', 'idea',...</td>\n",
       "      <td>['think', 'like', 'impact', 'understanding', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T19:00:35.094469600Z",
     "start_time": "2025-12-22T18:56:45.788357Z"
    }
   },
   "cell_type": "code",
   "source": "df_clean.to_pickle('dfs/preprocessed-cleaned-df.pkl')",
   "id": "e3d4b17eb831f780",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
